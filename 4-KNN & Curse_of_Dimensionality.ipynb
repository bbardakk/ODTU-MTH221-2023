{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b03a4ec-0396-422b-8a49-c1d6ed8aff7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2936b42a02147f59740702abd897ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='k', max=20, min=1), RadioButtons(description='weight', o…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Load the dataset\n",
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data[:, [0, 1]], iris.target, test_size=0.3, random_state=42)\n",
    "\n",
    "def plot_knn_with_test_data(k, weight, p):\n",
    "    model = KNeighborsClassifier(n_neighbors=k, weights=weight, p=p)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    # Create color maps\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "    cmap_bold = ['darkred', 'darkgreen', 'darkblue']\n",
    "    \n",
    "    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
    "    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, .01), np.arange(y_min, y_max, .01))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light, shading='auto')\n",
    "    \n",
    "    # Plot the training points\n",
    "    for i, color in zip(range(3), cmap_bold):\n",
    "        idx = np.where(y_train == i)\n",
    "        plt.scatter(X_train[idx, 0], X_train[idx, 1], c=color, label=f\"{iris.target_names[i]} (Train)\",\n",
    "                    edgecolor='black', s=20, alpha=0.6)\n",
    "        \n",
    "    predictions = model.predict(X_test)\n",
    "    # Plot the testing points\n",
    "    for i, color in zip(range(3), cmap_bold):\n",
    "        idx = np.where(y_test == i)\n",
    "        plt.scatter(X_test[idx, 0], X_test[idx, 1], c=color, label=f\"{iris.target_names[i]} (Test)\",\n",
    "                    edgecolor='black', s=50, marker='D')\n",
    "\n",
    "    # Highlight the misclassified points\n",
    "    misclassified = X_test[y_test != predictions]\n",
    "    plt.scatter(misclassified[:, 0], misclassified[:, 1], c='none', edgecolor='red', s=200, linewidth=1.5, marker='o')\n",
    "    \n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(f\"k-NN Classification Results (Test Accuracy: {accuracy:.2f})\\n\"\n",
    "              f\"K={k}, Weight={weight}, p={p}\")\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(\n",
    "    plot_knn_with_test_data, \n",
    "    k=widgets.IntSlider(min=1, max=20, step=1, value=5), \n",
    "    weight=widgets.RadioButtons(options=['uniform', 'distance'], value='uniform'),\n",
    "    p=widgets.FloatSlider(min=1, max=5, value=2)\n",
    ")\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '500px'\n",
    "interactive_plot\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e41ee-92c3-497a-8c90-a1b34545222b",
   "metadata": {},
   "source": [
    "### Understanding the Impact of K, Weight, and P in k-NN Algorithm\n",
    "\n",
    "In the k-NN algorithm, three crucial parameters—`K`, `Weight`, and `P`—play a significant role in determining the model's performance and behavior. Let's delve deeper into the essence of each:\n",
    "\n",
    "#### 1. **K Value:**\n",
    "In k-NN, the `K` value represents the number of neighbors we consider to predict the class of a new, unseen instance.\n",
    "\n",
    "- **Small K Values:**\n",
    "  - **Pros:** Able to capture finer details of data.\n",
    "  - **Cons:** More sensitive to noise, with a higher risk of overfitting.\n",
    "- **Large K Values:**\n",
    "  - **Pros:** Tends to make more stable and generalized predictions.\n",
    "  - **Cons:** Potentially smoothens over the finer details of class boundaries, risking underfitting.\n",
    "\n",
    "#### 2. **Weight:**\n",
    "The `Weight` parameter determines the influence each of the `K` neighbors has on the final prediction.\n",
    "\n",
    "- **Uniform Weight:**\n",
    "  - Every neighbor has an equal vote, regardless of its distance from the test instance. It treats every neighbor with equal importance.\n",
    "- **Distance Weight:**\n",
    "  - Closer neighbors to the test instance have a greater influence on the prediction. The influence or the weight is inversely proportional to the distance of the neighbor from the test instance, allowing the model to be more sensitive to local variations.\n",
    "\n",
    "#### 3. **P Value:**\n",
    "The `P` parameter is associated with the Minkowski distance metric, a generalized distance metric that includes both Euclidean (p=2) and Manhattan (p=1) distances.\n",
    "\n",
    "- **Small P Value (e.g., 1 - Manhattan Distance):**\n",
    "  - Emphasizes the difference along individual dimensions and is effective in grid-like path structures.\n",
    "- **Large P Value (e.g., 2 - Euclidean Distance):**\n",
    "  - Considers the cumulative difference across dimensions, suitable for circular or elliptical path structures.\n",
    "\n",
    "### Summary:\n",
    "- **Adjusting K:** Manages the trade-off between noise sensitivity and detail smoothing, controlling the granularity of the classification.\n",
    "- **Choosing Weight:** Decides the influence of neighbors, allowing either equal contribution or weighted contribution based on proximity.\n",
    "- **Tuning P Value:** Affects the distance metric used, influencing the perception of 'closeness' between instances in the feature space.\n",
    "\n",
    "Through interactive experimentation with these parameters, we can gain insights into their impact, refine the model's behavior, and optimize its performance for various scenarios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9084d31f-e59c-4cca-bb08-f21ecebf67e8",
   "metadata": {},
   "source": [
    "## Curse of Dimensionalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9235a87-6a9b-4e08-af76-820c91a434b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c38f0ecffb4e4eab0ca90d7a984c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='Num Points:', max=500, min=50, step=10), IntSlider(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_curse_of_dimensionality(num_points, max_dimension):\n",
    "    def average_distance(num_dimensions):\n",
    "        \"\"\"Calculate the average pairwise Euclidean distance between random points in a given dimension.\"\"\"\n",
    "        # Generate random points\n",
    "        points = np.random.rand(num_points, num_dimensions)\n",
    "\n",
    "        total_distance = 0\n",
    "        count = 0\n",
    "        for i in range(num_points):\n",
    "            for j in range(i+1, num_points):\n",
    "                total_distance += np.linalg.norm(points[i] - points[j])\n",
    "                count += 1\n",
    "\n",
    "        return total_distance / count\n",
    "\n",
    "    # Compute average distances for each dimension\n",
    "    dimensions = range(1, max_dimension+1)\n",
    "    distances = [average_distance(dim) for dim in dimensions]\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(dimensions, distances)\n",
    "    plt.xlabel('Dimensions')\n",
    "    plt.ylabel('Average Distance')\n",
    "    plt.title('Curse of Dimensionality: Average Distance Between Points')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widgets\n",
    "points_slider = widgets.IntSlider(value=100, min=50, max=500, step=10, description=\"Num Points:\")\n",
    "dimension_slider = widgets.IntSlider(value=50, min=2, max=200, step=1, description=\"Max Dimension:\")\n",
    "\n",
    "interactive_plot = widgets.interactive(plot_curse_of_dimensionality, num_points=points_slider, max_dimension=dimension_slider)\n",
    "output = interactive_plot.children[-1]\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4665d72-26c4-4e80-9677-14cd6f114eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4882e2c2b8418caf0e479b6d2c70a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='Num Points:', max=500, min=50, step=10), IntSlider(val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def plot_distance_distribution(num_points, num_dimensions, bins=30):\n",
    "    \"\"\"Visualize the distribution of distances in a given dimension.\"\"\"\n",
    "    # Generate random points\n",
    "    points = np.random.rand(num_points, num_dimensions)\n",
    "    \n",
    "    distances = []\n",
    "    for i in range(num_points):\n",
    "        for j in range(i+1, num_points):\n",
    "            distances.append(np.linalg.norm(points[i] - points[j])) ## L2 norm in default\n",
    "            \n",
    "    # Plot histogram of distances\n",
    "    plt.hist(distances, bins=bins, alpha=0.7, label=f\"{num_dimensions} dimensions\")\n",
    "    plt.legend()\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Number of Point Pairs')\n",
    "    plt.title(f'Distribution of Pairwise Distances for {num_points} Points in {num_dimensions} Dimensions')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Interactive widgets\n",
    "points_slider = widgets.IntSlider(value=100, min=50, max=500, step=10, description=\"Num Points:\")\n",
    "dimension_slider = widgets.IntSlider(value=10, min=2, max=2000, step=1, description=\"Dimension:\")\n",
    "bins_slider = widgets.IntSlider(value=30, min=10, max=100, step=1, description=\"Bins:\")\n",
    "\n",
    "interactive_plot = widgets.interactive(plot_distance_distribution, num_points=points_slider, num_dimensions=dimension_slider, bins=bins_slider)\n",
    "display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129c9725-ca67-4f2a-a5f2-0ac4be0f203b",
   "metadata": {},
   "source": [
    "### Understanding the Terminologies and Parameters in the Visualization:\n",
    "\n",
    "#### 1. **Distance:**\n",
    "   In the context of the visualized graph, \"Distance\" represents the computed spatial separation between pairs of data points in a high-dimensional space. It quantifies how far apart the individual data points are, using a defined metric like Euclidean or Manhattan, considering the specified number of dimensions (`max_dims`).\n",
    "\n",
    "#### 2. **Bins:**\n",
    "   \"Bins\" in the histogram refer to the intervals or range of values used to group the distances. Each bin represents a specific range of distances, and the frequency within each bin indicates how many distances in the dataset fall within that range. Adjusting the number of bins can provide a more refined or generalized view of the distance distributions, allowing for detailed analysis or broader overviews.\n",
    "\n",
    "#### 3. **Interpretation of num_points and max_dims:**\n",
    "   - **`num_points`:** Represents the number of data points generated in the high-dimensional space. Increasing this value will result in more distances calculated, offering a denser representation of the distance distribution in the specified dimensional space.\n",
    "   - **`max_dims`:** Denotes the number of dimensions considered in the space where data points are generated. Increasing the number of dimensions (max_dims) will generally result in an increase in the average distance between data points, illustrating the concept of the \"Curse of Dimensionality.\" Observing the variation in distance distribution with changing dimensions provides insights into how data behaves in high-dimensional spaces.\n",
    "\n",
    "### Final Thoughts:\n",
    "By interacting with and adjusting the parameters like `num_points`, `max_dims`, and `bins`, viewers can observe the nuances in distance distributions and frequency occurrences, gaining a practical understanding of the implications of high-dimensional spaces and the \"Curse of Dimensionality\" in distance-based algorithms like k-NN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007a5aca-0e1a-449b-829f-f4bd360decd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3432564520e47ecacf7473076edab6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1000, description='N', max=1000, min=10, step=10), IntSlider(value=10, d…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def curse_of_dimensionality(N=1000, K=10, dimensions=2):\n",
    "    # Generate N random points in the unit hypercube\n",
    "    points = np.random.rand(N, dimensions)\n",
    "    \n",
    "    # Choose a random point within the hypercube\n",
    "    random_point = np.random.rand(dimensions)\n",
    "    \n",
    "    # Calculate the distances from the random point to all other points\n",
    "    distances = np.linalg.norm(points - random_point, axis=1)\n",
    "    \n",
    "    # Get the indices of the K nearest points\n",
    "    k_nearest_indices = np.argsort(distances)[:K]\n",
    "    k_nearest_points = points[k_nearest_indices]\n",
    "    \n",
    "    # Calculate the bounding box (hypercube) for the K nearest points\n",
    "    min_bounds = k_nearest_points.min(axis=0)\n",
    "    max_bounds = k_nearest_points.max(axis=0)\n",
    "    l = max(max_bounds - random_point)\n",
    "\n",
    "    print(f\"For {dimensions} dimensions, the side length 'l' of the cube required to encapsulate {K} nearest points is approximately {l:.4f}.\")\n",
    "\n",
    "    # Visualization for 2D case\n",
    "    if dimensions == 2:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(points[:, 0], points[:, 1], color='blue', s=10, label=\"Random Points\")\n",
    "        ax.scatter(random_point[0], random_point[1], color='red', s=40, label=\"Randomly Chosen Point\")\n",
    "        \n",
    "        # Draw a rectangle for the bounding box of K nearest points\n",
    "        ax.add_patch(plt.Rectangle((random_point[0] - l/2, random_point[1] - l/2), l, l, fill=False, edgecolor='green', label=f\"Side length {l:.4f}\"))\n",
    "        \n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_aspect('equal', 'box')\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Interactive widget\n",
    "widgets.interactive(curse_of_dimensionality, N=(10, 1000, 10), K=(1, 100, 1), dimensions=(2, 100, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d15107-d6c7-4670-97ec-d97e1642259e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
